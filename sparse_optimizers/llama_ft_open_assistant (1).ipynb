{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df249412-569d-4f6e-963b-29529b23a545",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/conda/lib/python3.9/site-packages/trl/trainer/ppo_config.py:141: UserWarning: The `optimize_cuda_cache` arguement will be deprecated soon, please use `optimize_device_cache` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os, torch, logging\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, HfArgumentParser, TrainingArguments, pipeline, Trainer\n",
    "#from peft import LoraConfig, PeftModel\n",
    "from trl import SFTTrainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30296203-5fc5-4a19-80f7-cbea05c76800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "276.44112546673125\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.FloatTensor(120, 768, 3072)\n",
    "\n",
    "print (torch.numel(a)*a.element_size()/2024./2024.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87454858-b2da-42b0-8122-8f01656c713a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d82a447-112c-4509-8de8-124a3662444b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c26f0537-c595-4b7d-bcd5-622977b8f0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('llama.pickle', 'rb') as handle:\n",
    "       UV_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23c62068-fee5-4697-b484-ba9598966931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['up', 'down'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UV_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2a78061-b4db-46c0-8b2f-d68968a41131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4096, 4096])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UV_dict['up'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3466303-075e-4845-844d-f82ca4f0f48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in /home/user/conda/lib/python3.9/site-packages (1.11.4)\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /home/user/conda/lib/python3.9/site-packages (from scipy) (1.24.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20d28239-ab18-4f31-a889-a1c63ca731f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda:3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d36b66c6-515d-4609-82c7-6749435d1470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "  print (\"0\")\n",
    "else:\n",
    "  print (\"1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2577d6b-2246-4481-8f64-0989568804da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3237b18336bf498c9d718598b4cbd3d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model_name = \"TheBloke/Llama-2-7B-fp16\"\n",
    "refined_model = \"7b_opst\"\n",
    "# Tokenizer\n",
    "llama_tokenizer = AutoTokenizer.from_pretrained(base_model_name, trust_remote_code=True, max_length=512, truncation=True)\n",
    "llama_tokenizer.pad_token = llama_tokenizer.eos_token\n",
    "llama_tokenizer.padding_side = \"left\",  # Fix for fp16\n",
    "# Quantization Config\n",
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=False\n",
    ")\n",
    "# Model\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_name,\n",
    "    device_map=DEVICE,torch_dtype=torch.bfloat16\n",
    ")\n",
    "base_model.config.use_cache = False\n",
    "base_model.config.pretraining_tp = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9b21b5e-fbb7-4ef3-9e28-1367bacf9875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(base_model.model.layers[3].mlp.down_proj.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d016f5f-a2d3-4837-880b-2cf6793e0679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0-31): 32 x LlamaDecoderLayer(\n",
       "    (self_attn): LlamaAttention(\n",
       "      (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "      (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "      (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "      (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "      (rotary_emb): LlamaRotaryEmbedding()\n",
       "    )\n",
       "    (mlp): LlamaMLP(\n",
       "      (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "      (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "      (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "      (act_fn): SiLUActivation()\n",
       "    )\n",
       "    (input_layernorm): LlamaRMSNorm()\n",
       "    (post_attention_layernorm): LlamaRMSNorm()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b962f9f0-4531-4f0e-b31d-10d187836239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama_tokenizer.add_special_tokens({\n",
    "    \"eos_token\": llama_tokenizer.convert_ids_to_tokens(base_model.config.eos_token_id),\n",
    "    \"bos_token\": llama_tokenizer.convert_ids_to_tokens(base_model.config.bos_token_id),\n",
    "    \"unk_token\": llama_tokenizer.convert_ids_to_tokens(\n",
    "        base_model.config.pad_token_id if base_model.config.pad_token_id != -1 else tokenizer.pad_token_id\n",
    "    ),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0325d2a4-f687-40cf-a30b-8ab593217c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/OpenAssistant___parquet/OpenAssistant--oasst1-2960c57d7e52ab15/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/84437 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/84437 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function get_custom_dataset.<locals>.<lambda> at 0x7fa1653ff550> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9846 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9846 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/44042 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/44042 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/44042 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/OpenAssistant___parquet/OpenAssistant--oasst1-2960c57d7e52ab15/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4401 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/4401 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/518 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/518 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2241 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2241 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2241 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dataset\n",
    "from custom_dataset import get_custom_dataset\n",
    "training_data = get_custom_dataset(llama_tokenizer, split=\"train\")\n",
    "val_data = get_custom_dataset(llama_tokenizer, split=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83809bc-2cc3-4501-81c6-f85a8db70388",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data[5].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777247f3-03ec-4fec-8569-ea31850d93dd",
   "metadata": {},
   "source": [
    "## Freeze parts of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be7f89b6-5913-4f8d-bf07-a800c86b8287",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in base_model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd673823-87f1-42c4-aa1c-79cdfb96712a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(base_model.model.layers), 3):\n",
    "    for param in base_model.model.layers[i].mlp.parameters():\n",
    "        param.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f3c757-ce8e-40d4-97fb-26669b58281c",
   "metadata": {},
   "source": [
    "## Add lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ec24029-5b46-457d-b97f-cd50eeb76f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for pname, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            print(pname, param.numel())\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2cb1280-4e27-47a0-8398-c9954e82bc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "rank = 8\n",
    "target_modules = ['gate_proj', \"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"]\n",
    "ignore_modules = []\n",
    "# target_modules =  [\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"]\n",
    "# ignore_modules = ['down_proj', 'up_proj', 'gate_proj']\n",
    "# target_modules = ['down_proj', 'up_proj', 'gate_proj']\n",
    "# ignore_modules =  [\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"]\n",
    "alpha = 8\n",
    "init = 'lora'\n",
    "config = LoraConfig(\n",
    "    r=rank,\n",
    "    lora_alpha=alpha, \n",
    "    # target_modules=['k_proj', 'o_proj', 'down_proj', 'q_proj', 'up_proj', 'gate_proj', 'v_proj'], \n",
    "    target_modules=target_modules,\n",
    "    lora_dropout=0.05, \n",
    "    bias=\"none\", \n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54312b15-6110-4924-913b-995a9e9d5ef3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.0.self_attn.q_proj.lora_A.default.weight 32768\n",
      "model.layers.0.self_attn.q_proj.lora_B.default.weight 32768\n",
      "model.layers.0.self_attn.k_proj.lora_A.default.weight 32768\n",
      "model.layers.0.self_attn.k_proj.lora_B.default.weight 32768\n",
      "model.layers.0.self_attn.v_proj.lora_A.default.weight 32768\n",
      "model.layers.0.self_attn.v_proj.lora_B.default.weight 32768\n",
      "model.layers.0.self_attn.o_proj.lora_A.default.weight 32768\n",
      "model.layers.0.self_attn.o_proj.lora_B.default.weight 32768\n",
      "model.layers.0.mlp.gate_proj.lora_A.default.weight 32768\n",
      "model.layers.0.mlp.gate_proj.lora_B.default.weight 88064\n",
      "model.layers.1.self_attn.q_proj.lora_A.default.weight 32768\n",
      "model.layers.1.self_attn.q_proj.lora_B.default.weight 32768\n",
      "model.layers.1.self_attn.k_proj.lora_A.default.weight 32768\n",
      "model.layers.1.self_attn.k_proj.lora_B.default.weight 32768\n",
      "model.layers.1.self_attn.v_proj.lora_A.default.weight 32768\n",
      "model.layers.1.self_attn.v_proj.lora_B.default.weight 32768\n",
      "model.layers.1.self_attn.o_proj.lora_A.default.weight 32768\n",
      "model.layers.1.self_attn.o_proj.lora_B.default.weight 32768\n",
      "model.layers.1.mlp.gate_proj.lora_A.default.weight 32768\n",
      "model.layers.1.mlp.gate_proj.lora_B.default.weight 88064\n",
      "model.layers.2.self_attn.q_proj.lora_A.default.weight 32768\n",
      "model.layers.2.self_attn.q_proj.lora_B.default.weight 32768\n",
      "model.layers.2.self_attn.k_proj.lora_A.default.weight 32768\n",
      "model.layers.2.self_attn.k_proj.lora_B.default.weight 32768\n",
      "model.layers.2.self_attn.v_proj.lora_A.default.weight 32768\n",
      "model.layers.2.self_attn.v_proj.lora_B.default.weight 32768\n",
      "model.layers.2.self_attn.o_proj.lora_A.default.weight 32768\n",
      "model.layers.2.self_attn.o_proj.lora_B.default.weight 32768\n",
      "model.layers.2.mlp.gate_proj.lora_A.default.weight 32768\n",
      "model.layers.2.mlp.gate_proj.lora_B.default.weight 88064\n",
      "model.layers.3.self_attn.q_proj.lora_A.default.weight 32768\n",
      "model.layers.3.self_attn.q_proj.lora_B.default.weight 32768\n",
      "model.layers.3.self_attn.k_proj.lora_A.default.weight 32768\n",
      "model.layers.3.self_attn.k_proj.lora_B.default.weight 32768\n",
      "model.layers.3.self_attn.v_proj.lora_A.default.weight 32768\n",
      "model.layers.3.self_attn.v_proj.lora_B.default.weight 32768\n",
      "model.layers.3.self_attn.o_proj.lora_A.default.weight 32768\n",
      "model.layers.3.self_attn.o_proj.lora_B.default.weight 32768\n",
      "model.layers.3.mlp.gate_proj.lora_A.default.weight 32768\n",
      "model.layers.3.mlp.gate_proj.lora_B.default.weight 88064\n",
      "model.layers.4.self_attn.q_proj.lora_A.default.weight 32768\n",
      "model.layers.4.self_attn.q_proj.lora_B.default.weight 32768\n",
      "model.layers.4.self_attn.k_proj.lora_A.default.weight 32768\n",
      "model.layers.4.self_attn.k_proj.lora_B.default.weight 32768\n",
      "model.layers.4.self_attn.v_proj.lora_A.default.weight 32768\n",
      "model.layers.4.self_attn.v_proj.lora_B.default.weight 32768\n",
      "model.layers.4.self_attn.o_proj.lora_A.default.weight 32768\n",
      "model.layers.4.self_attn.o_proj.lora_B.default.weight 32768\n",
      "model.layers.4.mlp.gate_proj.lora_A.default.weight 32768\n",
      "model.layers.4.mlp.gate_proj.lora_B.default.weight 88064\n",
      "model.layers.5.self_attn.q_proj.lora_A.default.weight 32768\n",
      "model.layers.5.self_attn.q_proj.lora_B.default.weight 32768\n",
      "model.layers.5.self_attn.k_proj.lora_A.default.weight 32768\n",
      "model.layers.5.self_attn.k_proj.lora_B.default.weight 32768\n",
      "model.layers.5.self_attn.v_proj.lora_A.default.weight 32768\n",
      "model.layers.5.self_attn.v_proj.lora_B.default.weight 32768\n",
      "model.layers.5.self_attn.o_proj.lora_A.default.weight 32768\n",
      "model.layers.5.self_attn.o_proj.lora_B.default.weight 32768\n",
      "model.layers.5.mlp.gate_proj.lora_A.default.weight 32768\n",
      "model.layers.5.mlp.gate_proj.lora_B.default.weight 88064\n",
      "model.layers.6.self_attn.q_proj.lora_A.default.weight 32768\n",
      "model.layers.6.self_attn.q_proj.lora_B.default.weight 32768\n",
      "model.layers.6.self_attn.k_proj.lora_A.default.weight 32768\n",
      "model.layers.6.self_attn.k_proj.lora_B.default.weight 32768\n",
      "model.layers.6.self_attn.v_proj.lora_A.default.weight 32768\n",
      "model.layers.6.self_attn.v_proj.lora_B.default.weight 32768\n",
      "model.layers.6.self_attn.o_proj.lora_A.default.weight 32768\n",
      "model.layers.6.self_attn.o_proj.lora_B.default.weight 32768\n",
      "model.layers.6.mlp.gate_proj.lora_A.default.weight 32768\n",
      "model.layers.6.mlp.gate_proj.lora_B.default.weight 88064\n",
      "model.layers.7.self_attn.q_proj.lora_A.default.weight 32768\n",
      "model.layers.7.self_attn.q_proj.lora_B.default.weight 32768\n",
      "model.layers.7.self_attn.k_proj.lora_A.default.weight 32768\n",
      "model.layers.7.self_attn.k_proj.lora_B.default.weight 32768\n",
      "model.layers.7.self_attn.v_proj.lora_A.default.weight 32768\n",
      "model.layers.7.self_attn.v_proj.lora_B.default.weight 32768\n",
      "model.layers.7.self_attn.o_proj.lora_A.default.weight 32768\n",
      "model.layers.7.self_attn.o_proj.lora_B.default.weight 32768\n",
      "model.layers.7.mlp.gate_proj.lora_A.default.weight 32768\n",
      "model.layers.7.mlp.gate_proj.lora_B.default.weight 88064\n",
      "model.layers.8.self_attn.q_proj.lora_A.default.weight 32768\n",
      "model.layers.8.self_attn.q_proj.lora_B.default.weight 32768\n",
      "model.layers.8.self_attn.k_proj.lora_A.default.weight 32768\n",
      "model.layers.8.self_attn.k_proj.lora_B.default.weight 32768\n",
      "model.layers.8.self_attn.v_proj.lora_A.default.weight 32768\n",
      "model.layers.8.self_attn.v_proj.lora_B.default.weight 32768\n",
      "model.layers.8.self_attn.o_proj.lora_A.default.weight 32768\n",
      "model.layers.8.self_attn.o_proj.lora_B.default.weight 32768\n",
      "model.layers.8.mlp.gate_proj.lora_A.default.weight 32768\n",
      "model.layers.8.mlp.gate_proj.lora_B.default.weight 88064\n",
      "model.layers.9.self_attn.q_proj.lora_A.default.weight 32768\n",
      "model.layers.9.self_attn.q_proj.lora_B.default.weight 32768\n",
      "model.layers.9.self_attn.k_proj.lora_A.default.weight 32768\n",
      "model.layers.9.self_attn.k_proj.lora_B.default.weight 32768\n",
      "model.layers.9.self_attn.v_proj.lora_A.default.weight 32768\n",
      "model.layers.9.self_attn.v_proj.lora_B.default.weight 32768\n",
      "model.layers.9.self_attn.o_proj.lora_A.default.weight 32768\n",
      "model.layers.9.self_attn.o_proj.lora_B.default.weight 32768\n",
      "model.layers.9.mlp.gate_proj.lora_A.default.weight 32768\n",
      "model.layers.9.mlp.gate_proj.lora_B.default.weight 88064\n",
      "model.layers.10.self_attn.q_proj.lora_A.default.weight 32768\n",
      "model.layers.10.self_attn.q_proj.lora_B.default.weight 32768\n",
      "model.layers.10.self_attn.k_proj.lora_A.default.weight 32768\n",
      "model.layers.10.self_attn.k_proj.lora_B.default.weight 32768\n",
      "model.layers.10.self_attn.v_proj.lora_A.default.weight 32768\n",
      "model.layers.10.self_attn.v_proj.lora_B.default.weight 32768\n",
      "model.layers.10.self_attn.o_proj.lora_A.default.weight 32768\n",
      "model.layers.10.self_attn.o_proj.lora_B.default.weight 32768\n",
      "model.layers.10.mlp.gate_proj.lora_A.default.weight 32768\n",
      "model.layers.10.mlp.gate_proj.lora_B.default.weight 88064\n",
      "model.layers.11.self_attn.q_proj.lora_A.default.weight 32768\n",
      "model.layers.11.self_attn.q_proj.lora_B.default.weight 32768\n",
      "model.layers.11.self_attn.k_proj.lora_A.default.weight 32768\n",
      "model.layers.11.self_attn.k_proj.lora_B.default.weight 32768\n",
      "model.layers.11.self_attn.v_proj.lora_A.default.weight 32768\n",
      "model.layers.11.self_attn.v_proj.lora_B.default.weight 32768\n",
      "model.layers.11.self_attn.o_proj.lora_A.default.weight 32768\n",
      "model.layers.11.self_attn.o_proj.lora_B.default.weight 32768\n",
      "model.layers.11.mlp.gate_proj.lora_A.default.weight 32768\n",
      "model.layers.11.mlp.gate_proj.lora_B.default.weight 88064\n",
      "model.layers.12.self_attn.q_proj.lora_A.default.weight 32768\n",
      "model.layers.12.self_attn.q_proj.lora_B.default.weight 32768\n",
      "model.layers.12.self_attn.k_proj.lora_A.default.weight 32768\n",
      "model.layers.12.self_attn.k_proj.lora_B.default.weight 32768\n",
      "model.layers.12.self_attn.v_proj.lora_A.default.weight 32768\n",
      "model.layers.12.self_attn.v_proj.lora_B.default.weight 32768\n",
      "model.layers.12.self_attn.o_proj.lora_A.default.weight 32768\n",
      "model.layers.12.self_attn.o_proj.lora_B.default.weight 32768\n",
      "model.layers.12.mlp.gate_proj.lora_A.default.weight 32768\n",
      "model.layers.12.mlp.gate_proj.lora_B.default.weight 88064\n",
      "model.layers.13.self_attn.q_proj.lora_A.default.weight 32768\n",
      "model.layers.13.self_attn.q_proj.lora_B.default.weight 32768\n",
      "model.layers.13.self_attn.k_proj.lora_A.default.weight 32768\n",
      "model.layers.13.self_attn.k_proj.lora_B.default.weight 32768\n",
      "model.layers.13.self_attn.v_proj.lora_A.default.weight 32768\n",
      "model.layers.13.self_attn.v_proj.lora_B.default.weight 32768\n",
      "model.layers.13.self_attn.o_proj.lora_A.default.weight 32768\n",
      "model.layers.13.self_attn.o_proj.lora_B.default.weight 32768\n",
      "model.layers.13.mlp.gate_proj.lora_A.default.weight 32768\n",
      "model.layers.13.mlp.gate_proj.lora_B.default.weight 88064\n",
      "model.layers.14.self_attn.q_proj.lora_A.default.weight 32768\n",
      "model.layers.14.self_attn.q_proj.lora_B.default.weight 32768\n",
      "model.layers.14.self_attn.k_proj.lora_A.default.weight 32768\n",
      "model.layers.14.self_attn.k_proj.lora_B.default.weight 32768\n",
      "model.layers.14.self_attn.v_proj.lora_A.default.weight 32768\n",
      "model.layers.14.self_attn.v_proj.lora_B.default.weight 32768\n",
      "model.layers.14.self_attn.o_proj.lora_A.default.weight 32768\n",
      "model.layers.14.self_attn.o_proj.lora_B.default.weight 32768\n",
      "model.layers.14.mlp.gate_proj.lora_A.default.weight 32768\n",
      "model.layers.14.mlp.gate_proj.lora_B.default.weight 88064\n",
      "model.layers.15.self_attn.q_proj.lora_A.default.weight 32768\n",
      "model.layers.15.self_attn.q_proj.lora_B.default.weight 32768\n",
      "model.layers.15.self_attn.k_proj.lora_A.default.weight 32768\n",
      "model.layers.15.self_attn.k_proj.lora_B.default.weight 32768\n",
      "model.layers.15.self_attn.v_proj.lora_A.default.weight 32768\n",
      "model.layers.15.self_attn.v_proj.lora_B.default.weight 32768\n",
      "model.layers.15.self_attn.o_proj.lora_A.default.weight 32768\n",
      "model.layers.15.self_attn.o_proj.lora_B.default.weight 32768\n",
      "model.layers.15.mlp.gate_proj.lora_A.default.weight 32768\n",
      "model.layers.15.mlp.gate_proj.lora_B.default.weight 88064\n",
      "model.layers.16.self_attn.q_proj.lora_A.default.weight 32768\n",
      "model.layers.16.self_attn.q_proj.lora_B.default.weight 32768\n",
      "model.layers.16.self_attn.k_proj.lora_A.default.weight 32768\n",
      "model.layers.16.self_attn.k_proj.lora_B.default.weight 32768\n",
      "model.layers.16.self_attn.v_proj.lora_A.default.weight 32768\n",
      "model.layers.16.self_attn.v_proj.lora_B.default.weight 32768\n",
      "model.layers.16.self_attn.o_proj.lora_A.default.weight 32768\n",
      "model.layers.16.self_attn.o_proj.lora_B.default.weight 32768\n",
      "model.layers.16.mlp.gate_proj.lora_A.default.weight 32768\n",
      "model.layers.16.mlp.gate_proj.lora_B.default.weight 88064\n",
      "model.layers.17.self_attn.q_proj.lora_A.default.weight 32768\n",
      "model.layers.17.self_attn.q_proj.lora_B.default.weight 32768\n",
      "model.layers.17.self_attn.k_proj.lora_A.default.weight 32768\n",
      "model.layers.17.self_attn.k_proj.lora_B.default.weight 32768\n",
      "model.layers.17.self_attn.v_proj.lora_A.default.weight 32768\n",
      "model.layers.17.self_attn.v_proj.lora_B.default.weight 32768\n",
      "model.layers.17.self_attn.o_proj.lora_A.default.weight 32768\n",
      "model.layers.17.self_attn.o_proj.lora_B.default.weight 32768\n",
      "model.layers.17.mlp.gate_proj.lora_A.default.weight 32768\n",
      "model.layers.17.mlp.gate_proj.lora_B.default.weight 88064\n",
      "model.layers.18.self_attn.q_proj.lora_A.default.weight 32768\n",
      "model.layers.18.self_attn.q_proj.lora_B.default.weight 32768\n",
      "model.layers.18.self_attn.k_proj.lora_A.default.weight 32768\n",
      "model.layers.18.self_attn.k_proj.lora_B.default.weight 32768\n",
      "model.layers.18.self_attn.v_proj.lora_A.default.weight 32768\n",
      "model.layers.18.self_attn.v_proj.lora_B.default.weight 32768\n",
      "model.layers.18.self_attn.o_proj.lora_A.default.weight 32768\n",
      "model.layers.18.self_attn.o_proj.lora_B.default.weight 32768\n",
      "model.layers.18.mlp.gate_proj.lora_A.default.weight 32768\n",
      "model.layers.18.mlp.gate_proj.lora_B.default.weight 88064\n",
      "model.layers.19.self_attn.q_proj.lora_A.default.weight 32768\n",
      "model.layers.19.self_attn.q_proj.lora_B.default.weight 32768\n",
      "model.layers.19.self_attn.k_proj.lora_A.default.weight 32768\n",
      "model.layers.19.self_attn.k_proj.lora_B.default.weight 32768\n",
      "model.layers.19.self_attn.v_proj.lora_A.default.weight 32768\n",
      "model.layers.19.self_attn.v_proj.lora_B.default.weight 32768\n",
      "model.layers.19.self_attn.o_proj.lora_A.default.weight 32768\n",
      "model.layers.19.self_attn.o_proj.lora_B.default.weight 32768\n",
      "model.layers.19.mlp.gate_proj.lora_A.default.weight 32768\n",
      "model.layers.19.mlp.gate_proj.lora_B.default.weight 88064\n",
      "model.layers.20.self_attn.q_proj.lora_A.default.weight 32768\n",
      "model.layers.20.self_attn.q_proj.lora_B.default.weight 32768\n",
      "model.layers.20.self_attn.k_proj.lora_A.default.weight 32768\n",
      "model.layers.20.self_attn.k_proj.lora_B.default.weight 32768\n",
      "model.layers.20.self_attn.v_proj.lora_A.default.weight 32768\n",
      "model.layers.20.self_attn.v_proj.lora_B.default.weight 32768\n",
      "model.layers.20.self_attn.o_proj.lora_A.default.weight 32768\n",
      "model.layers.20.self_attn.o_proj.lora_B.default.weight 32768\n",
      "model.layers.20.mlp.gate_proj.lora_A.default.weight 32768\n",
      "model.layers.20.mlp.gate_proj.lora_B.default.weight 88064\n",
      "model.layers.21.self_attn.q_proj.lora_A.default.weight 32768\n",
      "model.layers.21.self_attn.q_proj.lora_B.default.weight 32768\n",
      "model.layers.21.self_attn.k_proj.lora_A.default.weight 32768\n",
      "model.layers.21.self_attn.k_proj.lora_B.default.weight 32768\n",
      "model.layers.21.self_attn.v_proj.lora_A.default.weight 32768\n",
      "model.layers.21.self_attn.v_proj.lora_B.default.weight 32768\n",
      "model.layers.21.self_attn.o_proj.lora_A.default.weight 32768\n",
      "model.layers.21.self_attn.o_proj.lora_B.default.weight 32768\n",
      "model.layers.21.mlp.gate_proj.lora_A.default.weight 32768\n",
      "model.layers.21.mlp.gate_proj.lora_B.default.weight 88064\n",
      "model.layers.22.self_attn.q_proj.lora_A.default.weight 32768\n",
      "model.layers.22.self_attn.q_proj.lora_B.default.weight 32768\n",
      "model.layers.22.self_attn.k_proj.lora_A.default.weight 32768\n",
      "model.layers.22.self_attn.k_proj.lora_B.default.weight 32768\n",
      "model.layers.22.self_attn.v_proj.lora_A.default.weight 32768\n",
      "model.layers.22.self_attn.v_proj.lora_B.default.weight 32768\n",
      "model.layers.22.self_attn.o_proj.lora_A.default.weight 32768\n",
      "model.layers.22.self_attn.o_proj.lora_B.default.weight 32768\n",
      "model.layers.22.mlp.gate_proj.lora_A.default.weight 32768\n",
      "model.layers.22.mlp.gate_proj.lora_B.default.weight 88064\n",
      "model.layers.23.self_attn.q_proj.lora_A.default.weight 32768\n",
      "model.layers.23.self_attn.q_proj.lora_B.default.weight 32768\n",
      "model.layers.23.self_attn.k_proj.lora_A.default.weight 32768\n",
      "model.layers.23.self_attn.k_proj.lora_B.default.weight 32768\n",
      "model.layers.23.self_attn.v_proj.lora_A.default.weight 32768\n",
      "model.layers.23.self_attn.v_proj.lora_B.default.weight 32768\n",
      "model.layers.23.self_attn.o_proj.lora_A.default.weight 32768\n",
      "model.layers.23.self_attn.o_proj.lora_B.default.weight 32768\n",
      "model.layers.23.mlp.gate_proj.lora_A.default.weight 32768\n",
      "model.layers.23.mlp.gate_proj.lora_B.default.weight 88064\n",
      "model.layers.24.self_attn.q_proj.lora_A.default.weight 32768\n",
      "model.layers.24.self_attn.q_proj.lora_B.default.weight 32768\n",
      "model.layers.24.self_attn.k_proj.lora_A.default.weight 32768\n",
      "model.layers.24.self_attn.k_proj.lora_B.default.weight 32768\n",
      "model.layers.24.self_attn.v_proj.lora_A.default.weight 32768\n",
      "model.layers.24.self_attn.v_proj.lora_B.default.weight 32768\n",
      "model.layers.24.self_attn.o_proj.lora_A.default.weight 32768\n",
      "model.layers.24.self_attn.o_proj.lora_B.default.weight 32768\n",
      "model.layers.24.mlp.gate_proj.lora_A.default.weight 32768\n",
      "model.layers.24.mlp.gate_proj.lora_B.default.weight 88064\n",
      "model.layers.25.self_attn.q_proj.lora_A.default.weight 32768\n",
      "model.layers.25.self_attn.q_proj.lora_B.default.weight 32768\n",
      "model.layers.25.self_attn.k_proj.lora_A.default.weight 32768\n",
      "model.layers.25.self_attn.k_proj.lora_B.default.weight 32768\n",
      "model.layers.25.self_attn.v_proj.lora_A.default.weight 32768\n",
      "model.layers.25.self_attn.v_proj.lora_B.default.weight 32768\n",
      "model.layers.25.self_attn.o_proj.lora_A.default.weight 32768\n",
      "model.layers.25.self_attn.o_proj.lora_B.default.weight 32768\n",
      "model.layers.25.mlp.gate_proj.lora_A.default.weight 32768\n",
      "model.layers.25.mlp.gate_proj.lora_B.default.weight 88064\n",
      "model.layers.26.self_attn.q_proj.lora_A.default.weight 32768\n",
      "model.layers.26.self_attn.q_proj.lora_B.default.weight 32768\n",
      "model.layers.26.self_attn.k_proj.lora_A.default.weight 32768\n",
      "model.layers.26.self_attn.k_proj.lora_B.default.weight 32768\n",
      "model.layers.26.self_attn.v_proj.lora_A.default.weight 32768\n",
      "model.layers.26.self_attn.v_proj.lora_B.default.weight 32768\n",
      "model.layers.26.self_attn.o_proj.lora_A.default.weight 32768\n",
      "model.layers.26.self_attn.o_proj.lora_B.default.weight 32768\n",
      "model.layers.26.mlp.gate_proj.lora_A.default.weight 32768\n",
      "model.layers.26.mlp.gate_proj.lora_B.default.weight 88064\n",
      "model.layers.27.self_attn.q_proj.lora_A.default.weight 32768\n",
      "model.layers.27.self_attn.q_proj.lora_B.default.weight 32768\n",
      "model.layers.27.self_attn.k_proj.lora_A.default.weight 32768\n",
      "model.layers.27.self_attn.k_proj.lora_B.default.weight 32768\n",
      "model.layers.27.self_attn.v_proj.lora_A.default.weight 32768\n",
      "model.layers.27.self_attn.v_proj.lora_B.default.weight 32768\n",
      "model.layers.27.self_attn.o_proj.lora_A.default.weight 32768\n",
      "model.layers.27.self_attn.o_proj.lora_B.default.weight 32768\n",
      "model.layers.27.mlp.gate_proj.lora_A.default.weight 32768\n",
      "model.layers.27.mlp.gate_proj.lora_B.default.weight 88064\n",
      "model.layers.28.self_attn.q_proj.lora_A.default.weight 32768\n",
      "model.layers.28.self_attn.q_proj.lora_B.default.weight 32768\n",
      "model.layers.28.self_attn.k_proj.lora_A.default.weight 32768\n",
      "model.layers.28.self_attn.k_proj.lora_B.default.weight 32768\n",
      "model.layers.28.self_attn.v_proj.lora_A.default.weight 32768\n",
      "model.layers.28.self_attn.v_proj.lora_B.default.weight 32768\n",
      "model.layers.28.self_attn.o_proj.lora_A.default.weight 32768\n",
      "model.layers.28.self_attn.o_proj.lora_B.default.weight 32768\n",
      "model.layers.28.mlp.gate_proj.lora_A.default.weight 32768\n",
      "model.layers.28.mlp.gate_proj.lora_B.default.weight 88064\n",
      "model.layers.29.self_attn.q_proj.lora_A.default.weight 32768\n",
      "model.layers.29.self_attn.q_proj.lora_B.default.weight 32768\n",
      "model.layers.29.self_attn.k_proj.lora_A.default.weight 32768\n",
      "model.layers.29.self_attn.k_proj.lora_B.default.weight 32768\n",
      "model.layers.29.self_attn.v_proj.lora_A.default.weight 32768\n",
      "model.layers.29.self_attn.v_proj.lora_B.default.weight 32768\n",
      "model.layers.29.self_attn.o_proj.lora_A.default.weight 32768\n",
      "model.layers.29.self_attn.o_proj.lora_B.default.weight 32768\n",
      "model.layers.29.mlp.gate_proj.lora_A.default.weight 32768\n",
      "model.layers.29.mlp.gate_proj.lora_B.default.weight 88064\n",
      "model.layers.30.self_attn.q_proj.lora_A.default.weight 32768\n",
      "model.layers.30.self_attn.q_proj.lora_B.default.weight 32768\n",
      "model.layers.30.self_attn.k_proj.lora_A.default.weight 32768\n",
      "model.layers.30.self_attn.k_proj.lora_B.default.weight 32768\n",
      "model.layers.30.self_attn.v_proj.lora_A.default.weight 32768\n",
      "model.layers.30.self_attn.v_proj.lora_B.default.weight 32768\n",
      "model.layers.30.self_attn.o_proj.lora_A.default.weight 32768\n",
      "model.layers.30.self_attn.o_proj.lora_B.default.weight 32768\n",
      "model.layers.30.mlp.gate_proj.lora_A.default.weight 32768\n",
      "model.layers.30.mlp.gate_proj.lora_B.default.weight 88064\n",
      "model.layers.31.self_attn.q_proj.lora_A.default.weight 32768\n",
      "model.layers.31.self_attn.q_proj.lora_B.default.weight 32768\n",
      "model.layers.31.self_attn.k_proj.lora_A.default.weight 32768\n",
      "model.layers.31.self_attn.k_proj.lora_B.default.weight 32768\n",
      "model.layers.31.self_attn.v_proj.lora_A.default.weight 32768\n",
      "model.layers.31.self_attn.v_proj.lora_B.default.weight 32768\n",
      "model.layers.31.self_attn.o_proj.lora_A.default.weight 32768\n",
      "model.layers.31.self_attn.o_proj.lora_B.default.weight 32768\n",
      "model.layers.31.mlp.gate_proj.lora_A.default.weight 32768\n",
      "model.layers.31.mlp.gate_proj.lora_B.default.weight 88064\n",
      "trainable params: 12255232 || all params: 6750670848 || trainable%: 0.18154095016543162\n"
     ]
    }
   ],
   "source": [
    "# rank 8: trainable params: 8388608 || all params: 3508809728 || trainable%: 0.23907275259355415\n",
    "# rank 64: trainable params: 67108864 || all params: 3567529984 || trainable%: 1.8811016109458436\n",
    "# rank 1: trainable params: 1048576 || all params: 3501469696 || trainable%: 0.029946739256314844\n",
    "# rank 16: trainable params: 16777216 || all params: 3517198336 || trainable%: 0.47700511592645084\n",
    "model = get_peft_model(base_model, config)\n",
    "print_trainable_parameters(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8603eaea-4c61-45c9-8876-3f5fd4795f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ecb64a44-53d9-4d04-91b1-c27fcd2ab7e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_data[6]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24c3ea81-fa82-4688-aa57-4b3f13702a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_config =  {\n",
    "    \"evaluation_strategy\": \"steps\",\n",
    "    \"per_device_train_batch_size\": 1,\n",
    "    \"per_device_eval_batch_size\": 1,\n",
    "    \"gradient_accumulation_steps\": 64,\n",
    "    \"eval_steps\": 75,\n",
    "    # \"eval_steps\": 3,\n",
    "    \"save_steps\": 75,\n",
    "    # \"save_steps\": 3,\n",
    "    \"logging_steps\": 5,\n",
    "    \"learning_rate\": 0.0003,\n",
    "    \"lr_scheduler_type\": \"cosine\",\n",
    "    \"warmup_steps\": 50,\n",
    "    # \"warmup_steps\": 5,\n",
    "    \"num_train_epochs\": 3,\n",
    "    # \"max_steps\": 15,\n",
    "    \"fp16\": False,\n",
    "    \"bf16\": True,\n",
    "    \"torch_compile\": False,\n",
    "    \"optim\": \"adamw_torch\"\n",
    "}\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "        output_dir=\"/home/jovyan/team_code/big_models\",\n",
    "        save_total_limit=5,\n",
    "        logging_first_step=True,\n",
    "        eval_delay=0,\n",
    "        seed=42,\n",
    "        data_seed=42,\n",
    "        load_best_model_at_end=True,\n",
    "        report_to=None,\n",
    "        ddp_find_unused_parameters=None,\n",
    "        # deepspeed=deepspeed_config,\n",
    "        **trainer_config\n",
    "    )\n",
    "training_args.local_rank = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d6e8c2a-31c8-4c2d-8c79-a1208047e10c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43f054b4-a7f0-427f-afe6-fab185ad5aba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78cb8d47-57bd-4094-b854-b23e99d6cc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainerCallback, TrainerCallback, TrainerState, TrainerControl\n",
    "\n",
    "class SavePeftModelCallback(TrainerCallback):\n",
    "    def on_save(\n",
    "        self,\n",
    "        args: TrainingArguments,\n",
    "        state: TrainerState,\n",
    "        control: TrainerControl,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \n",
    "        peft_model_path = \"/home/jovyan/team_code/big_models2/\"\n",
    "        \n",
    "        kwargs[\"model\"].save_pretrained(peft_model_path)\n",
    "        return control\n",
    "\n",
    "callbacks = [SavePeftModelCallback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd51b3e3-5411-4888-85ae-aef780283833",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_args = TrainingArguments(\n",
    "        output_dir=\"/home/jovyan/team_code/big_models\",\n",
    "        save_total_limit=5,\n",
    "        local_rank = 1,\n",
    "        logging_first_step=True,\n",
    "        eval_delay=0,\n",
    "        seed=42,\n",
    "        data_seed=42,\n",
    "        load_best_model_at_end=True,\n",
    "        report_to=None,\n",
    "        ddp_find_unused_parameters=None,\n",
    "        **trainer_config\n",
    "    )\n",
    "training_args.local_rank = -1\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=training_data,\n",
    "        callbacks = callbacks,\n",
    "        eval_dataset=val_data,\n",
    "        tokenizer=llama_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8ea471-6d2e-45db-b8d5-bc936849579c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/home/user/conda/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='408' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  2/408 : < :, Epoch 0.01/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea7468a-7743-4a77-8e06-e48121eb8e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuning.model.save_pretrained(\"/home/jovyan/team_code/big_models/llama-2-7b_8bit.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff50ef6-f61d-48cd-9d88-c2e2d3ba8477",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160d64a4-9573-4236-ba79-c2d0580b1736",
   "metadata": {},
   "outputs": [],
   "source": [
    "11110MiB used"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
