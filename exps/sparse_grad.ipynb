{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3030c161",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import transformers\n",
    "from transformers import AutoModel, BertTokenizerFast, BertConfig, BertModel\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.autograd\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.nn.parameter import Parameter,   UninitializedParameter\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40128ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_collecting_tensors(step, tensor1, tensor2=None):\n",
    "    '''собирает в тензор     '''\n",
    "    if step == 0:\n",
    "        return tensor1.unsqueeze(0)\n",
    "    else:\n",
    "        return torch.concatenate((tensor1, tensor2),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea1acd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6b3ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Tucker_Decomposition(tensor):\n",
    "    n1, n2, n3 = tensor.shape\n",
    "    u1, _, _ = torch.svd(torch.reshape(tensor, (n1, -1)))\n",
    "    u2, _, _ = torch.svd(torch.reshape(torch.permute(tensor, [1, 2, 0]), (n2, -1)))\n",
    "    u3, _, _ = torch.svd(torch.reshape(torch.permute(tensor, [2, 0, 1]), (n3, -1)))\n",
    "    return u1, u2, u3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a40f61",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_tucker_tensors(dict_layers):\n",
    "    '''делает словарь где ключом будет слой, а значением будет тензор'''        \n",
    "    dict_tensor = dict(zip(range(12), [[]]*12))\n",
    "    for key in dict_layers.keys():\n",
    "        dict_tensor[key].append(torch.cat(dict_layers[key], 2 ))\n",
    "    return dict_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55400afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_collecting_tensors(step, tensor1, tensor2=None):\n",
    "    '''собирает в тензор     '''\n",
    "    if step == 0:\n",
    "        return tensor1.unsqueeze(0)\n",
    "    else:\n",
    "        return torch.concatenate((tensor1, tensor2),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3ef84b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d068d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Tucker_Decomposition(tensor):\n",
    "    n1, n2, n3 = tensor.shape\n",
    "    u1, _, _ = torch.svd(torch.reshape(tensor, (n1, -1)))\n",
    "    u2, _, _ = torch.svd(torch.reshape(torch.permute(tensor, [1, 2, 0]), (n2, -1)))\n",
    "    u3, _, _ = torch.svd(torch.reshape(torch.permute(tensor, [2, 0, 1]), (n3, -1)))\n",
    "    return u1, u2, u3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b845e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tucker_tensors(dict_layers):\n",
    "    '''делает словарь где ключом будет слой, а значением будет тензор'''        \n",
    "    dict_tensor = dict(zip(range(12), [[]]*12))\n",
    "    for key in dict_layers.keys():\n",
    "        dict_tensor[key].append(torch.cat(dict_layers[key], 2 ))\n",
    "    return dict_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ef98dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearFunctionSparseGrad(torch.autograd.Function):\n",
    "\n",
    "        # Note that forward, setseup_context, and backward are @staticmethods\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, weight, bias, len_grads, treshold, U, VT):\n",
    "        treshold = treshold\n",
    "        if (len_grads < 30 ):    # space 1\n",
    "            ctx.save_for_backward(input, weight, bias)\n",
    "            return  input @ weight.T + bias\n",
    "        else:\n",
    "            #u1, U, VT = Tucker_Decomposition(torch.cat(MyLayer.grads))\n",
    "            input = input @ U.T ## Here change\n",
    "            ctx.save_for_backward(input, weight, bias, U, VT) # space 2\n",
    "        ctx.size = input.shape[0]\n",
    "        \n",
    "        #print (weight.shape)\n",
    "        #print (bias.shape)\n",
    "        #print (len(grads)),\n",
    "        #print (treshold)\n",
    "        #print (U.shape, VT.shape)\n",
    "        print('weight.T@ U', weight.T.shape, U.shape, VT.shape)\n",
    "        return  input  @ weight.T  @ VT.T + bias # space 2  # HERE change\n",
    "    \n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "\n",
    "        if len(ctx.saved_tensors) == 3:  # space 1\n",
    "            input, weight, bias = ctx.saved_tensors\n",
    "            grad_input = grad_weight = grad_bias = None\n",
    "            if ctx.needs_input_grad[0]:\n",
    "                grad_input = grad_output @ weight\n",
    "            if ctx.needs_input_grad[1]:\n",
    "                #print (grad_output.T.shape)\n",
    "                #print (input.shape)\n",
    "                grad_weight =  torch.einsum('ijk,kjl->il', grad_output.T, input)#grad_output.T @input\n",
    "  \n",
    "            if bias is not None and ctx.needs_input_grad[2]:\n",
    "                grad_bias = grad_output\n",
    "            \n",
    "        elif len(ctx.saved_tensors) == 5: # space 2\n",
    "\n",
    "            input, weight, bias, U, VT = ctx.saved_tensors\n",
    "            grad_input = grad_weight = grad_bias = None\n",
    "            # print (grad_output.shape, VT.T.shape, U.shape)\n",
    "            grad_output = grad_output # !!!! HERE change\n",
    "            if ctx.needs_input_grad[0]:\n",
    "                grad_input = grad_output @ weight\n",
    "            if ctx.needs_input_grad[1]:\n",
    "                grad_weight = torch.einsum('ijk,kjl->il', grad_output.T, input)#grad_output.T @input\n",
    "                print('grad_weight', grad_weight.shape, U.shape, VT.shape)\n",
    "                grad_weight = VT.T @ grad_weight  # !!!! HERE change\n",
    "                grad_weight = torch.where(torch.abs(grad_weight) >= 0.0, grad_weight, torch.tensor(0.0).to('cuda'))  ## возвращаем градиент в каком пространстве?? VERY IMPORTANT\n",
    "            if bias is not None and ctx.needs_input_grad[2]:\n",
    "                grad_bias = grad_output\n",
    "            \n",
    "        return grad_input, grad_weight, grad_bias, None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e42b4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4f15fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseGradLinear(torch.nn.Module):\n",
    "    __constants__ = ['in_features', 'out_features']\n",
    "    in_features: int\n",
    "    out_features: int\n",
    "    weight: Tensor\n",
    "\n",
    "    def __init__(self, in_features: int, out_features: int, bias: bool = True,\n",
    "                 device=None, dtype=None) -> None:\n",
    "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.empty(out_features, **factory_kwargs))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.grads = []\n",
    "        self.treshold = 1e-3\n",
    "        self.U = None\n",
    "        self.VT = None\n",
    "        self.len_grads = len(self.grads)\n",
    "        \n",
    "        \n",
    "    def create_UV(self):\n",
    "        print (\"self.len_grads\", self.len_grads)\n",
    "        if (self.len_grads >= 30):\n",
    "            self.grads = torch.stack(self.grads[:30])\n",
    "            u1, VT, U = Tucker_Decomposition(self.grads)\n",
    "            self.U = U.T\n",
    "            self.VT = VT.T\n",
    "            self.U.requires_grad = False\n",
    "            self.VT.requires_grad = False\n",
    "            #print (\"self.U\", self.U.shape, \"self.VT\", self.VT.shape)\n",
    "            self.weight = torch.nn.Parameter(self.VT.T@self.weight@self.U.T)#torch.nn.Parameter(self.U@self.weight@self.VT)\n",
    "        else:\n",
    "            print (\"please do 30 optimizer steps\")\n",
    "            \n",
    "        \n",
    "        \n",
    "    def from_linear(self, linear: nn.Linear, transpose=False):\n",
    "        if transpose:\n",
    "            self.weight = torch.nn.Parameter(linear.weight.data.T)\n",
    "        else:\n",
    "            self.weight = torch.nn.Parameter(linear.weight.data)\n",
    "        self.bias = torch.nn.Parameter(linear.bias.data.clone()) if linear.bias is not None else None\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        if ((self.U is None) and (self.VT is None) and len(self.grads)>=30):\n",
    "            print (\"created matrix\")\n",
    "            self.create_UV()\n",
    "            \n",
    "        \n",
    "        return LinearFunctionSparseGrad.apply(x, self.weight, self.bias, self.len_grads, self.treshold, self.U, self.VT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee2fb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eedcb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_bert_layers(model):\n",
    "    if hasattr(model, \"bert\") and hasattr(model.bert, \"encoder\"):\n",
    "        encoder = model.bert.encoder\n",
    "    elif hasattr(model, \"encoder\"):\n",
    "        encoder = model.encoder\n",
    "    else:\n",
    "        raise ValueError(\"Expected model to have attribute 'encoder' or 'bert.encoder'.\")\n",
    "\n",
    "    for i, layer in enumerate(model.bert.encoder.layer):\n",
    "        token_dim, hidden_dim = layer.intermediate.dense.weight.shape\n",
    "        #print (\"dense\")\n",
    "        #print (\"old shape\", token_dim, hidden_dim)\n",
    "        \n",
    "        new_layer = SparseGradLinear(token_dim, hidden_dim)\n",
    "\n",
    "        new_layer.from_linear(layer.intermediate.dense)\n",
    "\n",
    "        model.bert.encoder.layer[i].intermediate.dense = new_layer\n",
    "          \n",
    "        #print (\"new shape\", layer.intermediate.dense.weight.shape)\n",
    "        \n",
    "        token_dim, hidden_dim = layer.output.dense.weight.shape\n",
    "        #print (\"output\")\n",
    "        #print (\"old shape\", token_dim, hidden_dim)\n",
    "        \n",
    "        new_layer = SparseGradLinear(token_dim, hidden_dim)\n",
    "\n",
    "        new_layer.from_linear(layer.output.dense)\n",
    "\n",
    "        model.bert.encoder.layer[i].output.dense = new_layer\n",
    "          \n",
    "        #print (\"new shape\", layer.output.dense.weight.shape)\n",
    "        #print (\"\\n\\n\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd00502",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396aeccf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2609a906",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c299af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "light"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
