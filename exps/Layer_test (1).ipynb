{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d62971eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import transformers\n",
    "from transformers import AutoModel, BertTokenizerFast, BertConfig, BertModel\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.autograd\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.nn.parameter import Parameter,   UninitializedParameter\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a72ed39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_collecting_tensors(step, tensor1, tensor2=None):\n",
    "    '''собирает в тензор     '''\n",
    "    if step == 0:\n",
    "        return tensor1.unsqueeze(0)\n",
    "    else:\n",
    "        return torch.concatenate((tensor1, tensor2),0)\n",
    "    \n",
    "\n",
    "\n",
    "def Tucker_Decomposition(tensor):\n",
    "    n1, n2, n3 = tensor.shape\n",
    "    u1, _, _ = torch.svd(torch.reshape(tensor, (n1, -1)))\n",
    "    u2, _, _ = torch.svd(torch.reshape(torch.permute(tensor, [1, 2, 0]), (n2, -1)))\n",
    "    u3, _, _ = torch.svd(torch.reshape(torch.permute(tensor, [2, 0, 1]), (n3, -1)))\n",
    "    return u1, u2, u3\n",
    "\n",
    "\n",
    "def get_tucker_tensors(dict_layers):\n",
    "    '''делает словарь где ключом будет слой, а значением будет тензор'''        \n",
    "    dict_tensor = dict(zip(range(12), [[]]*12))\n",
    "    for key in dict_layers.keys():\n",
    "        dict_tensor[key].append(torch.cat(dict_layers[key], 2 ))\n",
    "    return dict_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99885ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLinearFunction(torch.autograd.Function):\n",
    "\n",
    "        # Note that forward, setseup_context, and backward are @staticmethods\n",
    "    @staticmethod\n",
    "    def forward(ctx,input, weight, bias, grads, treshold):\n",
    "        treshold = treshold\n",
    "        if ((len(grads) <30 )): \n",
    "\n",
    "            ctx.save_for_backward(input, weight, bias)\n",
    "        else:\n",
    "            u1, U, VT = Tucker_Decomposition(torch.cat(MyLayer.grads)) ## <- ???\n",
    "            ctx.save_for_backward(input,weight, bias, U, VT)\n",
    "        ctx.size = input.shape[0]\n",
    "\n",
    "        return  input @ weight.T  + bias\n",
    "    \n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "\n",
    "        if len(ctx.saved_tensors) == 3:\n",
    "#             print('before 30')\n",
    "            input,weight, bias = ctx.saved_tensors\n",
    "            grad_input = grad_weight = grad_bias = None\n",
    "            if ctx.needs_input_grad[0]:\n",
    "                grad_input = grad_output @ weight\n",
    "            if ctx.needs_input_grad[1]:\n",
    "                grad_weight =  grad_output.T @input\n",
    "  \n",
    "            if bias is not None and ctx.needs_input_grad[2]:\n",
    "                grad_bias = grad_output\n",
    "            \n",
    "        elif len(ctx.saved_tensors) == 5:\n",
    "\n",
    "            input, weight, bias, U, VT = ctx.saved_tensors\n",
    "            print(U)\n",
    "            print(VT)\n",
    "            grad_input = grad_weight = grad_bias = None\n",
    "            if ctx.needs_input_grad[0]:\n",
    "                grad_input = grad_output @ weight\n",
    "            if ctx.needs_input_grad[1]:\n",
    "                grad_weight = grad_output.T @input \n",
    "                grad_weight = U @  grad_weight @ VT\n",
    "                grad_weight = torch.where(torch.abs(grad_weight) >= treshold, grad_weight, 0)\n",
    "            if bias is not None and ctx.needs_input_grad[2]:\n",
    "                grad_bias = grad_output\n",
    "            \n",
    "        return grad_input, grad_weight, grad_bias, None, None\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e015304",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLinear(torch.nn.Module):\n",
    "    __constants__ = ['in_features', 'out_features']\n",
    "    in_features: int\n",
    "    out_features: int\n",
    "    weight: Tensor\n",
    "\n",
    "    def __init__(self, in_features: int, out_features: int, bias: bool = True,\n",
    "                 device=None, dtype=None) -> None:\n",
    "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.empty(out_features, **factory_kwargs))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.grads = []\n",
    "        self.treshold = 1e-3\n",
    "    def forward(self, x):\n",
    "            return MyLinearFunction.apply(x, self.weight, self.bias, self.grads, self.treshold)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4f4a159",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= torch.ones((1,10))\n",
    "a = torch.nn.Parameter(torch.randn((10,10)))\n",
    "b = torch.nn.Parameter(torch.randn((10,10)))\n",
    "c = torch.nn.Parameter(torch.randn((1, 10)))\n",
    "u = torch.randn((10,10)) \n",
    "vt = torch.randn((10,10))\n",
    "treshold = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17f7cd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "MyLayer = MyLinear(10, 10)\n",
    "MyLayer.weight = nn.Parameter(a, requires_grad = True)\n",
    "MyLayer.bias = nn.Parameter(c, requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0c90ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_layer = nn.Linear(10,10)\n",
    "gt_layer.weight = torch.nn.Parameter(a)\n",
    "gt_layer.bias = torch.nn.Parameter(c)\n",
    "optimizer_gt = torch.optim.Adam(gt_layer.parameters())\n",
    "criterion_gt = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40a7bc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = torch.nn.Parameter(torch.randn((1, 10)))\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(MyLayer.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e77bc826",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23652bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(30):\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    optimizer_gt.zero_grad()\n",
    "    \n",
    "    output = MyLayer(x)\n",
    "    w = gt_layer(x)\n",
    "    assert np.allclose(output.detach().numpy(), w.detach().numpy())\n",
    "    \n",
    "    loss = criterion(output, gt)\n",
    "    loss_gt = criterion_gt(w, gt)\n",
    "    \n",
    "    loss.backward()\n",
    "    loss_gt.backward()\n",
    "    \n",
    "#     print(i, gt_layer.weight.detach().numpy())\n",
    "#     print(MyLayer.weight.grad.detach().numpy())\n",
    "    assert np.allclose(MyLayer.weight.grad.detach().numpy(), gt_layer.weight.grad.detach().numpy())\n",
    "    \n",
    "    MyLayer.grads.append(MyLayer.weight.grad.unsqueeze(0))\n",
    "\n",
    "    optimizer.step()\n",
    "    optimizer_gt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3fc7de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3243, -0.0407,  0.2942, -0.4176,  0.4783,  0.0510, -0.2926, -0.5308,\n",
      "         -0.1217,  0.1371],\n",
      "        [-0.1233, -0.5508, -0.5759, -0.4176, -0.0267,  0.0794,  0.1278, -0.0800,\n",
      "          0.3484, -0.1556],\n",
      "        [ 0.1783,  0.4147, -0.2516, -0.3676,  0.0686,  0.3737, -0.0621,  0.0988,\n",
      "         -0.4063, -0.5242],\n",
      "        [ 0.4451, -0.2728,  0.3231, -0.4245, -0.4440, -0.1093, -0.4623,  0.1276,\n",
      "         -0.0368,  0.0494],\n",
      "        [ 0.1406,  0.5085,  0.2045, -0.2704, -0.0394, -0.0872,  0.1738, -0.1405,\n",
      "          0.7273, -0.1365],\n",
      "        [-0.2157, -0.3197,  0.4327,  0.2357,  0.0947,  0.0287, -0.0882,  0.1218,\n",
      "          0.1445, -0.7451],\n",
      "        [-0.3949,  0.1425, -0.0346, -0.3353,  0.0597, -0.6869,  0.0559,  0.4530,\n",
      "         -0.1533, -0.0541],\n",
      "        [-0.3477,  0.0199,  0.1977, -0.1675,  0.0142,  0.5893, -0.0297,  0.5764,\n",
      "          0.1838,  0.3118],\n",
      "        [-0.4397,  0.2589, -0.2905,  0.2014, -0.4200,  0.0061, -0.6235, -0.1550,\n",
      "          0.1453, -0.0652],\n",
      "        [ 0.3366,  0.0088, -0.2456,  0.1616,  0.6148, -0.1096, -0.4997,  0.2995,\n",
      "          0.2629,  0.0402]])\n",
      "tensor([[-3.1623e-01,  9.4868e-01,  1.7652e-07,  3.9227e-08,  9.8067e-09,\n",
      "          0.0000e+00, -9.8067e-09, -1.9613e-08,  2.4517e-08, -1.9613e-08],\n",
      "        [-3.1623e-01, -1.0541e-01,  9.4281e-01,  2.9293e-08,  2.2224e-08,\n",
      "          1.9868e-08, -2.3561e-09, -2.4580e-08, -1.3978e-08, -4.7122e-09],\n",
      "        [-3.1623e-01, -1.0541e-01, -1.1785e-01,  9.3541e-01,  2.7961e-07,\n",
      "         -1.5202e-08,  1.7813e-08, -2.9849e-08, -2.9331e-08,  3.5627e-08],\n",
      "        [-3.1623e-01, -1.0541e-01, -1.1785e-01, -1.3363e-01,  9.2582e-01,\n",
      "         -8.2434e-08,  2.3446e-08,  2.6119e-08,  3.4087e-08,  2.6358e-08],\n",
      "        [-3.1623e-01, -1.0541e-01, -1.1785e-01, -1.3363e-01, -1.5430e-01,\n",
      "          9.1287e-01,  7.1498e-08,  1.7301e-08,  2.0023e-08,  3.2441e-08],\n",
      "        [-3.1623e-01, -1.0541e-01, -1.1785e-01, -1.3363e-01, -1.5430e-01,\n",
      "         -1.8257e-01,  8.9443e-01,  2.4000e-09,  8.8474e-09, -7.0738e-05],\n",
      "        [-3.1623e-01, -1.0541e-01, -1.1785e-01, -1.3363e-01, -1.5430e-01,\n",
      "         -1.8257e-01, -2.2354e-01, -4.2301e-08, -2.4679e-08,  8.6604e-01],\n",
      "        [-3.1623e-01, -1.0541e-01, -1.1785e-01, -1.3363e-01, -1.5430e-01,\n",
      "         -1.8257e-01, -2.2363e-01, -5.7735e-01, -5.7735e-01, -2.8866e-01],\n",
      "        [-3.1623e-01, -1.0541e-01, -1.1785e-01, -1.3363e-01, -1.5430e-01,\n",
      "         -1.8257e-01, -2.2363e-01, -2.1132e-01,  7.8868e-01, -2.8866e-01],\n",
      "        [-3.1623e-01, -1.0541e-01, -1.1785e-01, -1.3363e-01, -1.5430e-01,\n",
      "         -1.8257e-01, -2.2363e-01,  7.8868e-01, -2.1132e-01, -2.8866e-01]])\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m loss_gt\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#     print(i, gt_layer.weight.detach().numpy())\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#     print(MyLayer.weight.grad.detach().numpy())\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39mallclose(MyLayer\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy(), gt_layer\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     18\u001b[0m MyLayer\u001b[38;5;241m.\u001b[39mgrads\u001b[38;5;241m.\u001b[39mappend(MyLayer\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m     20\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer.zero_grad()\n",
    "optimizer_gt.zero_grad()\n",
    "\n",
    "output = MyLayer(x)\n",
    "w = gt_layer(x)\n",
    "assert np.allclose(output.detach().numpy(), w.detach().numpy())\n",
    "\n",
    "loss = criterion(output, gt)\n",
    "loss_gt = criterion_gt(w, gt)\n",
    "\n",
    "loss.backward()\n",
    "loss_gt.backward()\n",
    "\n",
    "#     print(i, gt_layer.weight.detach().numpy())\n",
    "#     print(MyLayer.weight.grad.detach().numpy())\n",
    "assert np.allclose(MyLayer.weight.grad.detach().numpy(), gt_layer.weight.grad.detach().numpy())\n",
    "\n",
    "MyLayer.grads.append(MyLayer.weight.grad.unsqueeze(0))\n",
    "\n",
    "optimizer.step()\n",
    "optimizer_gt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b67aefdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "U_ = torch.tensor([[-0.3243, -0.0407,  0.2942, -0.4176,  0.4783,  0.0510, -0.2926, -0.5308,\n",
    "         -0.1217,  0.1371],\n",
    "        [-0.1233, -0.5508, -0.5759, -0.4176, -0.0267,  0.0794,  0.1278, -0.0800,\n",
    "          0.3484, -0.1556],\n",
    "        [ 0.1783,  0.4147, -0.2516, -0.3676,  0.0686,  0.3737, -0.0621,  0.0988,\n",
    "         -0.4063, -0.5242],\n",
    "        [ 0.4451, -0.2728,  0.3231, -0.4245, -0.4440, -0.1093, -0.4623,  0.1276,\n",
    "         -0.0368,  0.0494],\n",
    "        [ 0.1406,  0.5085,  0.2045, -0.2704, -0.0394, -0.0872,  0.1738, -0.1405,\n",
    "          0.7273, -0.1365],\n",
    "        [-0.2157, -0.3197,  0.4327,  0.2357,  0.0947,  0.0287, -0.0882,  0.1218,\n",
    "          0.1445, -0.7451],\n",
    "        [-0.3949,  0.1425, -0.0346, -0.3353,  0.0597, -0.6869,  0.0559,  0.4530,\n",
    "         -0.1533, -0.0541],\n",
    "        [-0.3477,  0.0199,  0.1977, -0.1675,  0.0142,  0.5893, -0.0297,  0.5764,\n",
    "          0.1838,  0.3118],\n",
    "        [-0.4397,  0.2589, -0.2905,  0.2014, -0.4200,  0.0061, -0.6235, -0.1550,\n",
    "          0.1453, -0.0652],\n",
    "        [ 0.3366,  0.0088, -0.2456,  0.1616,  0.6148, -0.1096, -0.4997,  0.2995,\n",
    "          0.2629,  0.0402]])\n",
    "VT_= torch.tensor([[-3.1623e-01,  9.4868e-01,  1.7652e-07,  3.9227e-08,  9.8067e-09,\n",
    "          0.0000e+00, -9.8067e-09, -1.9613e-08,  2.4517e-08, -1.9613e-08],\n",
    "        [-3.1623e-01, -1.0541e-01,  9.4281e-01,  2.9293e-08,  2.2224e-08,\n",
    "          1.9868e-08, -2.3561e-09, -2.4580e-08, -1.3978e-08, -4.7122e-09],\n",
    "        [-3.1623e-01, -1.0541e-01, -1.1785e-01,  9.3541e-01,  2.7961e-07,\n",
    "         -1.5202e-08,  1.7813e-08, -2.9849e-08, -2.9331e-08,  3.5627e-08],\n",
    "        [-3.1623e-01, -1.0541e-01, -1.1785e-01, -1.3363e-01,  9.2582e-01,\n",
    "         -8.2434e-08,  2.3446e-08,  2.6119e-08,  3.4087e-08,  2.6358e-08],\n",
    "        [-3.1623e-01, -1.0541e-01, -1.1785e-01, -1.3363e-01, -1.5430e-01,\n",
    "          9.1287e-01,  7.1498e-08,  1.7301e-08,  2.0023e-08,  3.2441e-08],\n",
    "        [-3.1623e-01, -1.0541e-01, -1.1785e-01, -1.3363e-01, -1.5430e-01,\n",
    "         -1.8257e-01,  8.9443e-01,  2.4000e-09,  8.8474e-09, -7.0738e-05],\n",
    "        [-3.1623e-01, -1.0541e-01, -1.1785e-01, -1.3363e-01, -1.5430e-01,\n",
    "         -1.8257e-01, -2.2354e-01, -4.2301e-08, -2.4679e-08,  8.6604e-01],\n",
    "        [-3.1623e-01, -1.0541e-01, -1.1785e-01, -1.3363e-01, -1.5430e-01,\n",
    "         -1.8257e-01, -2.2363e-01, -5.7735e-01, -5.7735e-01, -2.8866e-01],\n",
    "        [-3.1623e-01, -1.0541e-01, -1.1785e-01, -1.3363e-01, -1.5430e-01,\n",
    "         -1.8257e-01, -2.2363e-01, -2.1132e-01,  7.8868e-01, -2.8866e-01],\n",
    "        [-3.1623e-01, -1.0541e-01, -1.1785e-01, -1.3363e-01, -1.5430e-01,\n",
    "         -1.8257e-01, -2.2363e-01,  7.8868e-01, -2.1132e-01, -2.8866e-01]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c17c1d63",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39mallclose(MyLayer\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy(), U_\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m@\u001b[39m gt_layer\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;241m@\u001b[39m VT_\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert np.allclose(MyLayer.weight.grad.detach().numpy(), U_.detach().numpy()@ gt_layer.weight.grad.detach().numpy() @ VT_.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0bb3e194",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradd =  U_.detach().numpy()@ gt_layer.weight.grad.detach().numpy() @ VT_.detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "891f9446",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradd = np.where(np.abs(gradd) >= 1e-3, gradd, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2dd7c0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39mallclose(MyLayer\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy(),gradd)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert np.allclose(MyLayer.weight.grad.detach().numpy(),gradd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba75fcbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.2636096 ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 3.4004018 ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 2.9717562 ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.88249606,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 4.409864  ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.26655453,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.20412314,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 1.7021345 ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [-2.487134  ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [-0.10458184,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MyLayer.weight.grad.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b017d2f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.2639494 ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 3.400247  ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 2.9717925 ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.88257873,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 4.409724  ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.2671327 ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.20370713,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 1.7018244 ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [-2.487178  ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [-0.10447836,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradd"
   ]
  },
  {
   "cell_type": "raw",
   "id": "40dee5ae",
   "metadata": {},
   "source": [
    "gradd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0efadf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(30):\n",
    "    optimizer.zero_grad()\n",
    "    output = MyLayer(x)\n",
    "    loss = criterion(output, gt)\n",
    "  \n",
    "    loss.backward()\n",
    "    MyLayer.grads.append(MyLayer.weight.grad.unsqueeze(0))\n",
    "\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11afb51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()\n",
    "output = MyLayer(x)\n",
    "loss = criterion(output, gt)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259dd745",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
